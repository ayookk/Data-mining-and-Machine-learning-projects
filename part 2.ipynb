{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-26T21:07:54.823814Z",
     "start_time": "2024-11-26T21:07:52.613006Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor, export_text\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X_train = iris.data[:, [0, 1]]  \n",
    "y_train = iris.target.astype(float)\n",
    "h0 = np.mean(y_train)  \n",
    "print(f\"Initial weak classifier h0: {h0:.4f}\")\n",
    "H = []\n",
    "H.append(h0)\n",
    "T = 3\n",
    "for t in range(T):\n",
    "    print(f\"\\nIteration {t+1}:\")\n",
    "    y_pred = np.zeros_like(y_train) + H[0] \n",
    "    for h in H[1:]:\n",
    "        y_pred += h.predict(X_train)\n",
    "    print(f\"\\nFirst 5 predicted values 天(t-1):\")\n",
    "    print(y_pred[:5])\n",
    "    residuals = y_train - y_pred\n",
    "    print(f\"\\nFirst 5 residuals ri:\")\n",
    "    print(residuals[:5])\n",
    "    Y_train_new = residuals.copy()\n",
    "    print(f\"\\nFirst 5 values of revised Y_train:\")\n",
    "    print(Y_train_new[:5])\n",
    "    ht = DecisionTreeRegressor(max_depth=2)\n",
    "    ht.fit(X_train, Y_train_new) \n",
    "    print(f\"\\nTree structure for h{t+1}:\")\n",
    "    print(export_text(ht, feature_names=['X1', 'X2']))\n",
    "    y_pred_new = ht.predict(X_train)\n",
    "    print(f\"\\nFirst 5 predictions for h{t+1}:\")\n",
    "    print(y_pred_new[:5])\n",
    "    sum_residuals = np.sum([h.predict(X_train) for h in H[1:]], axis=0)\n",
    "    if sum_residuals.sum() < 0:\n",
    "        H.append(ht) \n",
    "        continue\n",
    "    else:\n",
    "        print(f\"H^({t-1}) is the final ensemble set.\")\n",
    "        break   \n",
    "print(\"\\nFinal ensemble size:\", len(H)) \n",
    "\n",
    "# Complete Gradient Boosting Implementation Explanation:\n",
    "#\n",
    "# 1. Data Preparation (18. 1-1):\n",
    "# - Loads iris dataset for regression\n",
    "# - Uses first two features as X_train\n",
    "# - Converts target to float for y_train\n",
    "#\n",
    "# 2. Initial Weak Classifier (18. 1-2):\n",
    "# - Calculates mean of y_train values as h0\n",
    "# - h0 serves as the first weak classifier\n",
    "# - Initializes ensemble H with h0\n",
    "#\n",
    "# 3. Boosting Loop Setup:\n",
    "# - Sets T=3 iterations (as specified)\n",
    "# - Creates empty list to store weak classifiers\n",
    "# - Prepares for iterative improvement\n",
    "#\n",
    "# 4. For Each Iteration t (18. 1-3):\n",
    "# - Calculates ensemble predictions 天(t-1):\n",
    "#   * Starts with h0 (mean value)\n",
    "#   * Adds predictions from all trees in ensemble\n",
    "#   * Gets current estimate for each data point\n",
    "#\n",
    "# - Computes residuals:\n",
    "#   * ri = yi - 天(t-1) for each point i\n",
    "#   * Shows how far current predictions are from true values\n",
    "#   * These residuals become new training targets\n",
    "#\n",
    "# - Updates training data:\n",
    "#   * Replaces Y_train with residual values\n",
    "#   * Allows next classifier to focus on errors\n",
    "#\n",
    "# 5. New Weak Classifier (18. 1-4):\n",
    "# - Creates decision tree regressor:\n",
    "#   * Uses max_depth=2 for weak learning\n",
    "#   * Fits tree to current residuals\n",
    "#\n",
    "# - Visualizes tree structure:\n",
    "#   * Shows split points and values\n",
    "#   * Uses export_text for tree visualization\n",
    "#\n",
    "# - Displays predictions:\n",
    "#   * Shows what new tree predicts\n",
    "#   * Helps track improvement\n",
    "#\n",
    "# 6. Convergence Check (18. 1-5):\n",
    "# - Checks if sum of residuals < 0\n",
    "# - If true: adds new tree to ensemble\n",
    "# - If false: stops and uses current ensemble\n",
    "#\n",
    "# 7. Key Concepts:\n",
    "# - Each iteration tries to correct previous mistakes\n",
    "# - Trees learn from residuals of ensemble\n",
    "# - Process continues until convergence or T iterations\n",
    "# - Final ensemble combines all weak learners\n",
    "#\n",
    "# 8. Implementation Notes:\n",
    "# - Uses sklearn's DecisionTreeRegressor\n",
    "# - Maintains list of all classifiers\n",
    "# - Prints intermediate results for tracking\n",
    "# - Shows residuals and predictions at each step"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weak classifier h0: 1.0000\n",
      "\n",
      "Iteration 1:\n",
      "\n",
      "First 5 predicted values 天(t-1):\n",
      "[1. 1. 1. 1. 1.]\n",
      "\n",
      "First 5 residuals ri:\n",
      "[-1. -1. -1. -1. -1.]\n",
      "\n",
      "First 5 values of revised Y_train:\n",
      "[-1. -1. -1. -1. -1.]\n",
      "\n",
      "Tree structure for h1:\n",
      "|--- X1 <= 5.55\n",
      "|   |--- X2 <= 2.80\n",
      "|   |   |--- value: [0.00]\n",
      "|   |--- X2 >  2.80\n",
      "|   |   |--- value: [-0.98]\n",
      "|--- X1 >  5.55\n",
      "|   |--- X1 <= 6.15\n",
      "|   |   |--- value: [0.19]\n",
      "|   |--- X1 >  6.15\n",
      "|   |   |--- value: [0.71]\n",
      "\n",
      "\n",
      "First 5 predictions for h1:\n",
      "[-0.9787234 -0.9787234 -0.9787234 -0.9787234 -0.9787234]\n",
      "H^(-1) is the final ensemble set.\n",
      "\n",
      "Final ensemble size: 1\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ee304b51f13d6fd3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
